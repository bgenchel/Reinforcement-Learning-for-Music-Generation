"""
taken from https://github.com/ZiJianZhao/SeqGAN-PyTorch
"""
import pdb
import torch
import torch.nn as nn
from functools import partial
from torch.autograd import Variable

from utils import constants as const
from utils import helpers as hlp


class Generator(nn.Module):
    """
    Simple 1-layer LSTM-RNN for sequence generation
    """
    def __init__(self, vocab_size, embed_dim, hidden_dim, device, use_cuda=True, **kwargs):
        super(Generator, self).__init__(**kwargs)
        # the number of discrete values an input can take on
        self.vocab_size = vocab_size
        self.embed_dim = embed_dim
        self.hidden_dim = hidden_dim
        self.device = device
        self.use_cuda = use_cuda
        self.num_layers = 2

        self.prepare_vars = partial(hlp.prepare_vars, self.use_cuda, self.device)

        self.embedder = nn.Embedding(vocab_size, embed_dim)

        self.chord_root_embedder = nn.Embedding(const.CHORD_ROOT_DIM, const.CHORD_ROOT_EMBED_DIM)
        self.chord_type_embedder = nn.Embedding(const.CHORD_TYPE_DIM, const.CHORD_TYPE_EMBED_DIM)

        chord_dim = const.CHORD_ROOT_EMBED_DIM + const.CHORD_TYPE_EMBED_DIM
        self.chord_encoder = nn.Sequential(
            nn.Linear(chord_dim, (const.CHORD_EMBED_DIM + chord_dim) // 2),
            nn.ReLU(),
            nn.Linear((const.CHORD_EMBED_DIM + chord_dim) // 2, const.CHORD_EMBED_DIM)
        )

        lstm_input_dim = const.CHORD_EMBED_DIM + embed_dim
        self.lstm = nn.LSTM(lstm_input_dim, hidden_dim, self.num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_dim, vocab_size)
        self.softmax = nn.LogSoftmax(dim=-1)
        self.init_params()
        return

    def init_params(self):
        for param in self.parameters():
            param.data.uniform_(-0.05, 0.05)
        return

    def init_hidden_and_cell(self, batch_size):
        hidden = Variable(torch.zeros((self.num_layers, batch_size, self.hidden_dim)))
        cell = Variable(torch.zeros((self.num_layers, batch_size, self.hidden_dim)))
        if self.use_cuda and torch.cuda.is_available():
            hidden, cell = hidden.cuda(), cell.cuda()
        return hidden, cell

    def forward(self, x, chord_roots, chord_types):
        # initial chord processing and formation
        cr_embeds = self.chord_root_embedder(chord_roots)
        ct_embeds = self.chord_type_embedder(chord_types)
        chord_encode = self.chord_encoder(torch.cat([cr_embeds, ct_embeds], 2))
        # embed ticks
        x_embeds = self.embedder(x)
        # pass it all through the lstm
        h0, c0 = self.init_hidden_and_cell(x.size(0))
        lstm_out, _ = self.lstm(torch.cat([x_embeds, chord_encode], 2), (h0, c0))
        # pred = self.softmax(self.fc(lstm_out.contiguous()(-1, self.hidden_dim)))
        pred = self.softmax(self.fc(lstm_out.contiguous()))
        return pred

    # a tool used for sampling; takes a hidden and cell state, and input and gives the next step
    def single_step(self, x, chord_root, chord_type, hidden, cell):
        """
        Args:
            x: (batch_size, 1) sequence of tokens generated by the generator
            chord_root: (batch_size, 1) sequence of tokens for stepwise chords
            chord_type: (batch_size, 1) sequence of tokens for chord type per step
            hidden: (1, batch_size, hidden_dim), lstm hidden state
            cell: (1, batch_size, hidden_dim), lstm cell state
        """
        # initial chord processing and formation
        cr_embed = self.chord_root_embedder(chord_root)
        ct_embed = self.chord_type_embedder(chord_type)
        chord_encode = self.chord_encoder(torch.cat([cr_embed, ct_embed], -1))
        # embed the actual tick
        x_embed = self.embedder(x)
        # pass it all through the lstm
        lstm_out, (hidden, cell) = self.lstm(torch.cat([x_embed, chord_encode], -1), (hidden, cell))
        # process the hidden state into a softmax distribution
        fc_out = self.fc(lstm_out.view(-1, self.hidden_dim))
        pred = self.softmax(fc_out)
        # return
        return pred, hidden, cell

    def sample(self, batch_size, seq_len, chord_roots, chord_types, seed=None):
        """
        this method creates (batch_size) sequences of length (seq_len).
        If no seed is provided, it begins with a single time step of length 0.
        If a seed is provided, it generates seq_len - seed_len samples.
        """
        samples = []
        hidden, cell = self.init_hidden_and_cell(batch_size)
        cr_symbols = chord_roots.chunk(chord_roots.size(1), dim=1)
        ct_symbols = chord_types.chunk(chord_types.size(1), dim=1)
        if seed is None:
            # if data is not provided, create zeros to stand in
            inpt = Variable(torch.zeros((batch_size, 1)).long())
            cr_inpt = Variable(torch.zeros((batch_size, 1)).long())
            ct_inpt = Variable(torch.zeros((batch_size, 1)).long())
            inpt, cr_inpt, ct_inpt = self.prepare_vars(inpt, cr_inpt, ct_inpt)
            for i in range(seq_len):
                output, hidden, cell = self.single_step(inpt, cr_inpt, ct_inpt, hidden, cell)
                inpt = torch.exp(output).multinomial(1)  # sample the softmax distribution once
                cr_inpt = cr_symbols[i]
                ct_inpt = ct_symbols[i]
                inpt, cr_inpt, ct_inpt = self.prepare_vars(inpt, cr_inpt, ct_inpt)

                samples.append(inpt)
        else:
            seed = self.prepare_vars(seed)
            # split up the samples into length 1 tensors
            seed_len = seed.size(1)
            seed_symbols = seed.chunk(seed_len, dim=1)  # each element becomes its own tensor
            samples.extend(seed_symbols)
            # run through the seed to set the network state
            for i in range(seed_len):
                inpt, cr_inpt, ct_inpt = self.prepare_vars(seed_symbols[i], cr_symbols[i], ct_symbols[i])
                output, hidden, cell = self.single_step(inpt, cr_inpt, ct_inpt, hidden, cell)

            inpt = torch.exp(output).multinomial(1)
            cr_inpt = cr_symbols[i]
            ct_inpt = ct_symbols[i]
            inpt, cr_inpt, ct_inpt = self.prepare_vars(inpt, cr_inpt, ct_inpt)
            # actual sampling occurs here
            for i in range(seed_len, seq_len):
                samples.append(inpt)

                output, hidden, cell = self.single_step(inpt, cr_inpt, ct_inpt, hidden, cell)

                inpt = torch.exp(output).multinomial(1)
                cr_inpt = cr_symbols[i]
                ct_inpt = ct_symbols[i]
                inpt, cr_inpt, ct_inpt = self.prepare_vars(inpt, cr_inpt, ct_inpt)

        return torch.cat(samples, dim=1)

    def flatten_parameters(self):
        self.lstm.flatten_parameters()
